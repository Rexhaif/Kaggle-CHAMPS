{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Graph creator**\n",
    "\n",
    "A graph is a relativly natural way of representing molecules, and many method make use of structuring the data in this way.\n",
    "\n",
    "This kernel shows a basic example of one can structure our data as a graph.   \n",
    "\n",
    "Here we will create an array for our node values, and an adjacency matrix for our edge values. \n",
    "\n",
    "\n",
    "(**Note**: One can argue whether an adjacency matrix is really the best way to go here as we have an undirected graph, and it is therefore a bit innefficienct ( n^2 as opposed to n(n-1)/2 ), but it is easy to work with)\n",
    "\n",
    "This is by no means the fastest way of doing this, but it is straightforward and only has to be run once, and the output can then be used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['predicting-molecular-properties-bonds', 'champs-scalar-coupling', 'angle-and-dihedral-for-the-champs-structures']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from scipy.spatial import distance_matrix\n",
    "\n",
    "from sklearn import preprocessing\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "datadir = \"../input/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in train, test and structures files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(datadir + 'champs-scalar-coupling/train.csv')\n",
    "test = pd.read_csv(datadir + 'champs-scalar-coupling/test.csv')\n",
    "structures = pd.read_csv(datadir + 'champs-scalar-coupling/structures.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in bonds files\n",
    "Taken from:   https://www.kaggle.com/asauve/dataset-with-number-of-bonds-between-atoms  \n",
    "(thanks Alexandre Sauv√©!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bonds = pd.read_csv(datadir + 'predicting-molecular-properties-bonds/train_bonds.csv')\n",
    "test_bonds = pd.read_csv(datadir + 'predicting-molecular-properties-bonds/test_bonds.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reads from angles file\n",
    "Taken from: https://www.kaggle.com/soerendip/calculate-angles-and-dihedrals-with-networkx\n",
    "(thanks Rakete!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "angs = pd.read_csv(datadir + \"angle-and-dihedral-for-the-champs-structures/angles.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize targets so they have are centered around 0 and have max of 1, and one-hot encode coupling types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_min  = train['scalar_coupling_constant'].min()\n",
    "scale_max  = train['scalar_coupling_constant'].max()\n",
    "scale_mid = (scale_max + scale_min)/2\n",
    "scale_norm = scale_max - scale_mid\n",
    "\n",
    "train['scalar_coupling_constant'] = (train['scalar_coupling_constant'] - scale_mid)/scale_norm\n",
    "\n",
    "# One hot encoding gets  too big for Kaggle, let's try label\n",
    "#train[['1JHC', '1JHN', '2JHC', '2JHH', '2JHN', '3JHC', '3JHH', '3JHN']] =  pd.get_dummies(train['type'])\n",
    "#test[['1JHC', '1JHN', '2JHC', '2JHH', '2JHN', '3JHC', '3JHH', '3JHN']]  =  pd.get_dummies(test['type'])\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(['1JHC', '1JHN', '2JHC', '2JHH', '2JHN', '3JHC', '3JHH', '3JHN'])\n",
    "train['l_type'] = (le.transform(train['type']) + 1)/8.\n",
    "test['l_type'] = (le.transform(test['type']) + 1)/8."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-process the structures by one-hot encoding the atom types, and normalize distances to have around max of 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "structures[['C', 'F' ,'H', 'N', 'O']] = pd.get_dummies(structures['atom'])\n",
    "structures[['x', 'y', 'z']] = structures[['x', 'y', 'z']]/10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process bonds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_bonds['nbond'] = test_bonds['nbond']/3\n",
    "train_bonds['nbond'] = train_bonds['nbond']/3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "angs['dihedral'] = angs['dihedral']/np.pi\n",
    "# Should I rather one-hot this?\n",
    "angs['shortest_path_n_bonds'] = angs['shortest_path_n_bonds']/6.0\n",
    "angs = angs.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find training and testing molecules, and split structrues into test and train. Then group by molecule\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mol_names = train['molecule_name'].unique()\n",
    "test_mol_names  = test['molecule_name'].unique()\n",
    "\n",
    "train_structures = structures.loc[structures['molecule_name'].isin(train_mol_names)]\n",
    "test_structures = structures.loc[structures['molecule_name'].isin(test_mol_names)]\n",
    "\n",
    "train_struct_group = train_structures.groupby('molecule_name')\n",
    "test_struct_group  = test_structures.groupby('molecule_name')\n",
    "\n",
    "train_group = train.groupby('molecule_name')\n",
    "test_group  = test.groupby('molecule_name')\n",
    "\n",
    "train_bond_group = train_bonds.groupby('molecule_name')\n",
    "test_bond_group  = test_bonds.groupby('molecule_name')\n",
    "\n",
    "train_angs = angs.loc[angs['molecule_name'].isin(train_mol_names)]\n",
    "test_angs = angs.loc[angs['molecule_name'].isin(test_mol_names)]\n",
    "\n",
    "train_angs_group = train_angs.groupby('molecule_name')\n",
    "test_angs_group  = test_angs.groupby('molecule_name')\n",
    "\n",
    "# Find max nodes in graph:\n",
    "max_size = train_struct_group.size().max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define node and edge values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Values our nodes will have\n",
    "node_vals = ['C', 'F' ,'H', 'N', 'O']#, 'x', 'y', 'z']\n",
    "#Values our edges will have (minus distance, for now)\n",
    "bond_vals = ['nbond']\n",
    "j_coup_vals = ['l_type']#'1JHC', '1JHN', '2JHC', '2JHH', '2JHN', '3JHC', '3JHH', '3JHN']\n",
    "ang_vals = ['shortest_path_n_bonds','cosinus','dihedral']\n",
    "edge_vals = j_coup_vals + bond_vals + ang_vals\n",
    "\n",
    "# Find amount of training molecules\n",
    "n_train_mols = len(train_mol_names)\n",
    "n_test_mols = len(test_mol_names)\n",
    "\n",
    "# Find dim of edges and nodes\n",
    "bond_dim  = len(bond_vals)\n",
    "j_coup_dim= len(j_coup_vals)\n",
    "ang_dim   = len(ang_vals)\n",
    "node_dim  = len(node_vals)\n",
    "edge_dim  = len(edge_vals) \n",
    "\n",
    "# Additional edge dims for distances \n",
    "add_edge_dim = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-allocate arrays that we will fill later\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_nodes_array     = np.zeros((n_train_mols, max_size, node_dim), dtype=np.float32) \n",
    "train_in_edges_array  = np.zeros((n_train_mols, max_size, max_size, edge_dim + add_edge_dim),dtype=np.float32) \n",
    "train_out_edges_array = np.zeros((n_train_mols, max_size, max_size, 1),dtype=np.float32) \n",
    "\n",
    "test_nodes_array     = np.zeros((n_test_mols, max_size, node_dim), dtype=np.float32) \n",
    "test_in_edges_array  = np.zeros((n_test_mols, max_size, max_size, edge_dim + add_edge_dim),dtype=np.float32) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_arrs(val_group, struct_group, bond_group, ang_group, test):\n",
    "    i = 0\n",
    "    for values, structs, bonds, angles in zip(val_group, struct_group, bond_group, ang_group):\n",
    "        if (not i%1000):\n",
    "            print(i)\n",
    "\n",
    "        # Calculate distances\n",
    "        distances = np.zeros((max_size, max_size, 1))\n",
    "        coords = structs[1][['x','y','z']].values\n",
    "        dists  = distance_matrix(coords, coords)\n",
    "        distances[:dists.shape[0],:dists.shape[1], 0] = dists \n",
    "        \n",
    "        # Create nodes\n",
    "        mol_info = structs[1][node_vals].values\n",
    "        nodes = np.zeros((max_size, node_dim))\n",
    "        nodes[:mol_info.shape[0], :mol_info.shape[1]] = mol_info\n",
    "\n",
    "        # Create edges\n",
    "        in_feats = np.zeros((max_size, max_size, j_coup_dim))\n",
    "        ind = values[1][['atom_index_0', 'atom_index_1' ]].values\n",
    "        in_feats[ind[:,0], ind[:,1], 0:j_coup_dim] = values[1][j_coup_vals].values\n",
    "        in_feats[ind[:,1], ind[:,0], 0:j_coup_dim] = in_feats[ind[:,0], ind[:,1], 0:j_coup_dim]\n",
    "\n",
    "        # Create bonds\n",
    "        in_bonds = np.zeros((max_size, max_size, bond_dim))\n",
    "        ind_bonds = bonds[1][['atom_index_0', 'atom_index_1' ]].values\n",
    "        in_bonds[ind_bonds[:,0], ind_bonds[:,1]] = bonds[1][bond_vals].values\n",
    "        in_bonds[ind_bonds[:,1], ind_bonds[:,0]] = in_bonds[ind_bonds[:,0], ind_bonds[:,1]]\n",
    "        \n",
    "        # Create angles\n",
    "        ind_angs = angles[1][['atom_index_0', 'atom_index_1' ]].values\n",
    "        ang_mat  = np.zeros((max_size, max_size, ang_dim))\n",
    "        ang_mat[ind_angs[:,0], ind_angs[:,1]]  = angles[1][ang_vals]\n",
    "        ang_mat[ind_angs[:,1], ind_angs[:,0]]  = ang_mat[ind_angs[:,0], ind_angs[:,1]]\n",
    "        \n",
    "        # concat all edge values \n",
    "        in_edges = np.concatenate((in_feats, in_bonds, ang_mat, distances),axis=2)\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        if not test:           \n",
    "            out_edges = np.zeros((max_size, max_size, 1))\n",
    "            out_edges[ind[:,0], ind[:,1], 0] = values[1]['scalar_coupling_constant' ].values\n",
    "            out_edges[ind[:,1], ind[:,0], 0] = out_edges[ind[:,0], ind[:,1], 0]\n",
    "        \n",
    "\n",
    "            train_nodes_array[i]      = nodes\n",
    "            train_in_edges_array[i]   = in_edges\n",
    "            train_out_edges_array[i]  = out_edges\n",
    "        else:\n",
    "            test_nodes_array[i]      = nodes\n",
    "            test_in_edges_array[i]   = in_edges\n",
    "        i = i + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n",
      "51000\n",
      "52000\n",
      "53000\n",
      "54000\n",
      "55000\n",
      "56000\n",
      "57000\n",
      "58000\n",
      "59000\n",
      "60000\n",
      "61000\n",
      "62000\n",
      "63000\n",
      "64000\n",
      "65000\n",
      "66000\n",
      "67000\n",
      "68000\n",
      "69000\n",
      "70000\n",
      "71000\n",
      "72000\n",
      "73000\n",
      "74000\n",
      "75000\n",
      "76000\n",
      "77000\n",
      "78000\n",
      "79000\n",
      "80000\n",
      "81000\n",
      "82000\n",
      "83000\n",
      "84000\n",
      "85000\n"
     ]
    }
   ],
   "source": [
    "make_arrs(train_group, train_struct_group, train_bond_group, train_angs_group, test = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n"
     ]
    }
   ],
   "source": [
    "make_arrs(test_group, test_struct_group, test_bond_group, test_angs_group, test = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save as numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"nodes_train.npy\" , train_nodes_array)\n",
    "np.save(\"in_edges_train.npy\" , train_in_edges_array)\n",
    "np.save(\"out_edges_train.npy\" , train_out_edges_array)\n",
    "\n",
    "np.save(\"nodes_test.npy\" , test_nodes_array)\n",
    "np.save(\"in_edges_test.npy\" , test_in_edges_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
